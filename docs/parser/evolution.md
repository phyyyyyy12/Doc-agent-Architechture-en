# Parser 模块演进：从“暴力切分”到“结构化感知”

### 📌 初始方案：固定字符长度切分 (Fixed-size Chunking)
* **做法**：每 500 个字符强制切一段，重叠 50 个字符。
* **痛点**：
    * **语义断裂**：经常把一个完整的代码块从中间切断，导致 Agent 无法理解代码逻辑。
    * **上下文丢失**：切出来的 Chunk 如果没有标题，Agent 只看到一段文字，不知道它属于哪个业务模块。

### 🔄 关键改动：基于 Markdown 结构的智能分块 (Smart Structure-Aware Chunking)

为了让 RAG 更精准，我重构了解析器，核心逻辑如下：

1.  **基于标题切分 (Heading-based)**：
    * 以 `#` 到 `###` 作为自然边界。优先保证同一个小标题下的内容完整性。
2.  **上下文继承与 Breadcrumb (面包屑策略)**：
    * **实现**：每个 Chunk 都会自动注入其所属的标题路径。
    * **示例**：`[用户中心 -> 接口文档 -> 登录接口]：这是具体的参数说明...`
    * **价值**：即使该 Chunk 被单独检索出来，Agent 也能通过前缀瞬间定位其语义背景。
3.  **块边界保护 (Boundary Protection)**：
    * **代码块保护**：正则识别 ` ``` ` 符号，严禁在代码块内部切分，保证代码逻辑完整。
    * **表格保护**：识别 Markdown 表格结构，确保一行数据不被拆分到两个 Chunk 中。
4.  **元数据丰富化 (Metadata Enrichment)**：
    * 每个 Chunk 自动携带：source_file（源文件路径）、breadcrumb（标题路径，格式：文件名 > 父标题 > 子标题）、parent_header（父级标题路径）、heading（当前标题）、heading_level（标题层级，1-6）、format（文件格式）、inherited_heading（是否继承标题）等标签，方便后续进行元数据过滤。

### 💡 自身思考 (Insights)
1.  **RAG 的胜负手在数据清洗**：很多人在拼命调优 Embedding 模型，但实际经验告诉我们，**解析时多做一分努力，检索时能省十分力气**。
2.  **放弃 RST 的决策**：虽然 RST 功能强大，但对于企业级内部文档，Markdown 的普及率和解析生态更优。为了保持架构的轻量和解析的精准，我选择了“断舍离”，专攻 Markdown 的深度解析。
3.  **未来的挑战**：当 Markdown 中嵌套了复杂的 Mermaid 图表或 LaTeX 公式时，如何保持其语义不丢失，是下一阶段需要思考的命题。
